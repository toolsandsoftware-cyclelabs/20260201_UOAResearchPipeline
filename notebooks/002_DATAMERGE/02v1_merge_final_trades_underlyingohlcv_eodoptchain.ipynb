{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69224865",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "================================================================================\n",
    "Phase 02B: Per-Ticker Merging of EOD Historical Options Chain Data\n",
    "================================================================================\n",
    "\n",
    "Script Name: Phase_02B_merge_eod_chain.py\n",
    "Pipeline Position: Phase 02B sits between Phase 02A (underlying OHLCV merge) and \n",
    "                   feature engineering (Phase 03+), completing the data enrichment \n",
    "                   pipeline by adding options-specific market data.\n",
    "\n",
    "--------------------------------------------------------------------------------\n",
    "PURPOSE\n",
    "--------------------------------------------------------------------------------\n",
    "This module enriches options trade data (already merged with underlying OHLCV \n",
    "from Phase 02A) with EOD historical options chain data from Intrinio. It joins \n",
    "intraday options trades with per-contract EOD data including open interest, \n",
    "implied volatility, and Greeks (delta, gamma, theta, vega) for downstream \n",
    "anomaly detection analysis.\n",
    "\n",
    "Key Operations:\n",
    "  1. Per-Ticker Processing — Processes trades grouped by underlying ticker for \n",
    "     efficient memory usage and targeted output files\n",
    "  2. EOD Chain Data Enrichment — Maps current-day open interest, implied \n",
    "     volatility, and Greeks to each trade\n",
    "  3. Previous Day Open Interest — Retrieves open interest from the previous \n",
    "     trading day (accounting for weekends and holidays via NYSE calendar)\n",
    "  4. Ticker Format Conversion — Converts between EOD chain format \n",
    "     (e.g., AAPL240315C00075000) and OCC format (e.g., O:AAPL240315C00075000)\n",
    "  5. Data Export — Saves enriched trade data as per-ticker, date-partitioned \n",
    "     parquet files\n",
    "\n",
    "--------------------------------------------------------------------------------\n",
    "DIRECTORY STRUCTURE\n",
    "--------------------------------------------------------------------------------\n",
    "project_root/\n",
    "│\n",
    "├── Phase_02B_merge_eod_chain.py        # This script\n",
    "│\n",
    "├── input/\n",
    "│   ├── TRADES_WITH_UNDERLYING/         # Output from Phase 02A (input)\n",
    "│   │   ├── 2024-02-01.parquet\n",
    "│   │   ├── 2024-02-02.parquet\n",
    "│   │   └── ...\n",
    "│   │\n",
    "│   └── EOD_OPTIONS_CHAIN/              # EOD chain data from Intrinio (FLAT)\n",
    "│       ├── AAPL_2024-02-01.csv         # NOT nested in subfolders!\n",
    "│       ├── TSLA_2024-02-01.csv\n",
    "│       └── ...\n",
    "│\n",
    "└── output/                             # Enriched trades data (output)\n",
    "    ├── AAPL_comptrades_2024-02-01.parquet\n",
    "    ├── TSLA_comptrades_2024-02-01.parquet\n",
    "    └── ...\n",
    "\n",
    "--------------------------------------------------------------------------------\n",
    "INPUT SPECIFICATIONS\n",
    "--------------------------------------------------------------------------------\n",
    "1. Options Trades Data (trades_input_path/)\n",
    "   - Filename Format: YYYY-MM-DD.parquet (output from Phase 02A)\n",
    "   - Required Columns:\n",
    "     * ticker      — Option contract ticker in OCC format (e.g., O:AAPL240315C00075000)\n",
    "     * underlying  — Underlying stock ticker symbol (e.g., AAPL, TSLA)\n",
    "\n",
    "2. EOD Options Chain Data (eod_chain_input_path/)\n",
    "   - Filename Format: {TICKER}_{DATE}.csv (FLAT structure, NOT nested)\n",
    "   - Example: AAPL_2024-02-01.csv\n",
    "   - Required Columns:\n",
    "     * code               — Option contract code (e.g., AAPL240315C00075000)\n",
    "                            NOTE: Use 'code' column, NOT 'ticker' column!\n",
    "     * open_interest      — Total open contracts\n",
    "     * implied_volatility — IV calculated using Black-Scholes\n",
    "     * delta              — Rate of change vs $1 underlying move\n",
    "     * gamma              — Rate of change of delta\n",
    "     * theta              — Time decay\n",
    "     * vega               — Sensitivity to IV changes\n",
    "\n",
    "--------------------------------------------------------------------------------\n",
    "OUTPUT SPECIFICATIONS\n",
    "--------------------------------------------------------------------------------\n",
    "- Filename Format: {TICKER}_comptrades_YYYY-MM-DD.parquet\n",
    "- Example: AAPL_comptrades_2024-02-01.parquet\n",
    "\n",
    "New columns added to output:\n",
    "  * open_interest_now       — EOD open interest for the trade date\n",
    "  * open_interest_yesterday — EOD open interest for previous trading day\n",
    "  * implied_volatility      — EOD implied volatility\n",
    "  * grk_delta               — EOD delta\n",
    "  * grk_gamma               — EOD gamma\n",
    "  * grk_theta               — EOD theta\n",
    "  * grk_vega                — EOD vega\n",
    "  * trade_date              — Trade date in YYYY-MM-DD format\n",
    "\n",
    "Note: If an option contract is not found in EOD chain data, enrichment \n",
    "columns will be NaN.\n",
    "\n",
    "--------------------------------------------------------------------------------\n",
    "CONFIGURATION\n",
    "--------------------------------------------------------------------------------\n",
    "Modify the CONFIG dictionary:\n",
    "\n",
    "CONFIG = {\n",
    "    \"start_date\": \"2024-02-01\",           # Start date (YYYY-MM-DD)\n",
    "    \"end_date\": \"2024-12-31\",             # End date (YYYY-MM-DD)\n",
    "    \"tickers\": [\"AAPL\", \"TSLA\"],          # List of tickers, or None for all\n",
    "    \"trades_input_path\": \"./input/TRADES_WITH_UNDERLYING\",\n",
    "    \"eod_chain_input_path\": \"./input/EOD_OPTIONS_CHAIN\",\n",
    "    \"output_path\": \"./output\",\n",
    "}\n",
    "\n",
    "Parameters:\n",
    "  * start_date          — First date to process (inclusive)\n",
    "  * end_date            — Last date to process (inclusive)\n",
    "  * tickers             — List of underlying tickers, or None to process all\n",
    "  * trades_input_path   — Path to Phase 02A output (parquet files)\n",
    "  * eod_chain_input_path— Path to EOD options chain CSV files (FLAT structure)\n",
    "  * output_path         — Path for enriched output files\n",
    "\n",
    "--------------------------------------------------------------------------------\n",
    "USAGE\n",
    "--------------------------------------------------------------------------------\n",
    "Basic execution:\n",
    "    python Phase_02B_merge_eod_chain.py\n",
    "\n",
    "Process specific tickers for one day:\n",
    "    CONFIG[\"tickers\"] = [\"AAPL\", \"TSLA\", \"NVDA\"]\n",
    "    CONFIG[\"start_date\"] = \"2024-02-01\"\n",
    "    CONFIG[\"end_date\"] = \"2024-02-01\"\n",
    "\n",
    "Process ALL tickers for a date range:\n",
    "    CONFIG[\"tickers\"] = None\n",
    "    CONFIG[\"start_date\"] = \"2024-02-01\"\n",
    "    CONFIG[\"end_date\"] = \"2024-12-31\"\n",
    "\n",
    "Expected console output:\n",
    "    Processing 252 trading days from 2024-02-01 to 2024-12-31\n",
    "    ############################################################\n",
    "    # DATE: 2024-02-01\n",
    "    ############################################################\n",
    "    Loaded 5,793,340 trades from .../2024-02-01.parquet\n",
    "    ============================================================\n",
    "    Processing AAPL for 2024-02-01\n",
    "    ============================================================\n",
    "    Found 12,487 trades for AAPL\n",
    "    Loaded 2,358 chain records from .../AAPL_2024-02-01.csv\n",
    "    Previous trading day: 2024-01-31\n",
    "    EOD match rate: 11,892/12,487 trades (95.2%)\n",
    "    Written 12,487 rows to .../AAPL_comptrades_2024-02-01.parquet\n",
    "\n",
    "--------------------------------------------------------------------------------\n",
    "DEPENDENCIES\n",
    "--------------------------------------------------------------------------------\n",
    "Required:\n",
    "  * pandas                  — Data manipulation\n",
    "  * numpy                   — Numerical operations\n",
    "  * pyarrow                 — Parquet file I/O\n",
    "\n",
    "Optional:\n",
    "  * pandas_market_calendars — NYSE trading calendar for previous trading day\n",
    "                              calculation (falls back to weekday logic if unavailable)\n",
    "\n",
    "Install:\n",
    "    pip install pandas numpy pyarrow pandas_market_calendars\n",
    "\n",
    "--------------------------------------------------------------------------------\n",
    "GITHUB LOCATION\n",
    "--------------------------------------------------------------------------------\n",
    "  * Owner: toolsandsoftware@cyclelabs.net\n",
    "  * Repo:  20260201_UOAResearchPipeline\n",
    "  * Path:  notebooks/002_DATAMERGING/02v1_merge_eod_options_chain.py\n",
    "  * Link:  https://github.com/toolsandsoftware-cyclelabs/20260201_UOAResearchPipeline\n",
    "\n",
    "================================================================================\n",
    "\"\"\"\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore', category=DeprecationWarning)\n",
    "warnings.filterwarnings('ignore', category=FutureWarning)\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime, timedelta\n",
    "import os\n",
    "import re\n",
    "from pathlib import Path\n",
    "\n",
    "# Try to import trading calendar - fallback to simple logic if unavailable\n",
    "try:\n",
    "    import pandas_market_calendars as mcal\n",
    "    NYSE_CALENDAR = mcal.get_calendar('NYSE')\n",
    "    HAS_MARKET_CALENDAR = True\n",
    "except ImportError:\n",
    "    HAS_MARKET_CALENDAR = False\n",
    "    print(\"Warning: pandas_market_calendars not installed. Using fallback trading day logic.\")\n",
    "    print(\"Install with: pip install pandas_market_calendars\")\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# CONFIGURATION - MODIFY THESE AS NEEDED\n",
    "# =============================================================================\n",
    "\n",
    "CONFIG = {\n",
    "    # -------------------------------------------------------------------------\n",
    "    # DATE RANGE\n",
    "    # -------------------------------------------------------------------------\n",
    "    \"start_date\": \"2023-12-04\",      # Start date (YYYY-MM-DD)\n",
    "    \"end_date\": \"2023-12-04\",        # End date (YYYY-MM-DD)\n",
    "    \n",
    "    # -------------------------------------------------------------------------\n",
    "    # TICKERS TO PROCESS\n",
    "    # -------------------------------------------------------------------------\n",
    "    # Set to a list of underlying tickers to process specific ones:\n",
    "    #   [\"AAPL\", \"TSLA\", \"NVDA\", \"SPY\"]\n",
    "    # Set to None to process ALL underlyings found in the trades file:\n",
    "    #   None\n",
    "    \"tickers\": None,\n",
    "    \n",
    "    # -------------------------------------------------------------------------\n",
    "    # INPUT PATHS (Local filesystem or mounted GCS paths)\n",
    "    # -------------------------------------------------------------------------\n",
    "    # Trades data: expects files named YYYY-MM-DD.parquet containing all trades\n",
    "    \"trades_input_path\": \"/path/to/trades\",\n",
    "    \n",
    "    # EOD chain data: expects files named {TICKER}_{DATE}.csv in FLAT structure\n",
    "    # Example: /path/to/eod/AAPL_2023-12-04.csv (NOT /path/to/eod/AAPL/AAPL_2023-12-04.csv)\n",
    "    \"eod_chain_input_path\": \"/path/to/eod/output\",\n",
    "    \n",
    "    # -------------------------------------------------------------------------\n",
    "    # OUTPUT PATH\n",
    "    # -------------------------------------------------------------------------\n",
    "    # Output files will be named: {ticker}_comptrades_YYYY-MM-DD.parquet\n",
    "    # Example: AAPL_comptrades_2023-12-04.parquet\n",
    "    \"output_path\": \"/path/to/output\",\n",
    "}\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# TRADING CALENDAR FUNCTIONS\n",
    "# =============================================================================\n",
    "\n",
    "def get_trading_days_in_range(start_date: str, end_date: str) -> list:\n",
    "    \"\"\"Get all trading days in a date range\"\"\"\n",
    "    if HAS_MARKET_CALENDAR:\n",
    "        schedule = NYSE_CALENDAR.schedule(start_date=start_date, end_date=end_date)\n",
    "        return [d.strftime(\"%Y-%m-%d\") for d in schedule.index]\n",
    "    else:\n",
    "        # Fallback: return all weekdays (won't account for holidays)\n",
    "        dates = []\n",
    "        current = datetime.strptime(start_date, \"%Y-%m-%d\")\n",
    "        end = datetime.strptime(end_date, \"%Y-%m-%d\")\n",
    "        while current <= end:\n",
    "            if current.weekday() < 5:  # Monday = 0, Friday = 4\n",
    "                dates.append(current.strftime(\"%Y-%m-%d\"))\n",
    "            current += timedelta(days=1)\n",
    "        return dates\n",
    "\n",
    "\n",
    "def get_previous_trading_day(date_str: str) -> str:\n",
    "    \"\"\"\n",
    "    Get the previous trading day accounting for weekends and holidays.\n",
    "    \n",
    "    Args:\n",
    "        date_str: Date in YYYY-MM-DD format\n",
    "        \n",
    "    Returns:\n",
    "        Previous trading day in YYYY-MM-DD format\n",
    "    \"\"\"\n",
    "    if HAS_MARKET_CALENDAR:\n",
    "        # Look back up to 10 days to find previous trading day\n",
    "        current_date = datetime.strptime(date_str, \"%Y-%m-%d\")\n",
    "        lookback_start = (current_date - timedelta(days=10)).strftime(\"%Y-%m-%d\")\n",
    "        lookback_end = (current_date - timedelta(days=1)).strftime(\"%Y-%m-%d\")\n",
    "        \n",
    "        schedule = NYSE_CALENDAR.schedule(start_date=lookback_start, end_date=lookback_end)\n",
    "        if len(schedule) > 0:\n",
    "            return schedule.index[-1].strftime(\"%Y-%m-%d\")\n",
    "        else:\n",
    "            # Fallback if no trading days found\n",
    "            return (current_date - timedelta(days=1)).strftime(\"%Y-%m-%d\")\n",
    "    else:\n",
    "        # Fallback: skip weekends only\n",
    "        current_date = datetime.strptime(date_str, \"%Y-%m-%d\")\n",
    "        previous_date = current_date - timedelta(days=1)\n",
    "        \n",
    "        # Skip weekends\n",
    "        while previous_date.weekday() >= 5:  # Saturday = 5, Sunday = 6\n",
    "            previous_date -= timedelta(days=1)\n",
    "        \n",
    "        return previous_date.strftime(\"%Y-%m-%d\")\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# TICKER FORMAT CONVERSION\n",
    "# =============================================================================\n",
    "\n",
    "def convert_to_occ_format(ticker_str: str) -> str:\n",
    "    \"\"\"\n",
    "    Convert EOD format to OCC format\n",
    "    Example: A240315C00075000 -> O:A240315C00075000\n",
    "    \"\"\"\n",
    "    if pd.isna(ticker_str):\n",
    "        return ticker_str\n",
    "    if not str(ticker_str).startswith(\"O:\"):\n",
    "        return f\"O:{ticker_str}\"\n",
    "    return ticker_str\n",
    "\n",
    "\n",
    "def extract_underlying_from_option_ticker(option_ticker: str) -> str:\n",
    "    \"\"\"\n",
    "    Extract underlying ticker from OCC format option ticker\n",
    "    Example: O:AAPL240315C00075000 -> AAPL\n",
    "             O:A240315C00075000 -> A\n",
    "    \"\"\"\n",
    "    if pd.isna(option_ticker):\n",
    "        return None\n",
    "    \n",
    "    # Remove O: prefix if present\n",
    "    ticker = str(option_ticker).replace(\"O:\", \"\")\n",
    "    \n",
    "    # Find where the date starts (6 digits YYMMDD)\n",
    "    match = re.match(r'^([A-Z]+)', ticker)\n",
    "    if match:\n",
    "        return match.group(1)\n",
    "    return None\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# FILE I/O FUNCTIONS\n",
    "# =============================================================================\n",
    "\n",
    "def read_trades_file(trades_path: str, date_str: str) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Read trades parquet file for a specific date.\n",
    "    Expected filename: YYYY-MM-DD.parquet (contains all tickers for that day)\n",
    "    \"\"\"\n",
    "    filepath = os.path.join(trades_path, f\"{date_str}.parquet\")\n",
    "    \n",
    "    if not os.path.exists(filepath):\n",
    "        print(f\"Warning: Trades file not found - {filepath}\")\n",
    "        return None\n",
    "    \n",
    "    # Use pyarrow directly to avoid pandas extension type conflicts\n",
    "    try:\n",
    "        import pyarrow.parquet as pq\n",
    "        table = pq.read_table(filepath)\n",
    "        df = table.to_pandas()\n",
    "    except Exception as e:\n",
    "        print(f\"PyArrow read failed ({e}), trying pandas directly...\")\n",
    "        df = pd.read_parquet(filepath, engine='pyarrow')\n",
    "    \n",
    "    print(f\"Loaded {len(df):,} trades from {filepath}\")\n",
    "    return df\n",
    "\n",
    "\n",
    "def read_eod_chain_file(eod_path: str, ticker: str, date_str: str) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Read EOD chain CSV file for a specific ticker and date.\n",
    "    Expected filename: {TICKER}_{DATE}.csv (flat structure)\n",
    "    \"\"\"\n",
    "    filepath = os.path.join(eod_path, f\"{ticker}_{date_str}.csv\")\n",
    "    \n",
    "    if not os.path.exists(filepath):\n",
    "        print(f\"Warning: EOD chain file not found - {filepath}\")\n",
    "        return None\n",
    "    \n",
    "    df = pd.read_csv(filepath)\n",
    "    print(f\"Loaded {len(df):,} chain records from {filepath}\")\n",
    "    return df\n",
    "\n",
    "\n",
    "def write_output_parquet(df: pd.DataFrame, output_path: str, ticker: str, date_str: str):\n",
    "    \"\"\"\n",
    "    Write merged data to parquet file.\n",
    "    Output filename: {ticker}_comptrades_YYYY-MM-DD.parquet\n",
    "    \"\"\"\n",
    "    os.makedirs(output_path, exist_ok=True)\n",
    "    filepath = os.path.join(output_path, f\"{ticker}_comptrades_{date_str}.parquet\")\n",
    "    \n",
    "    # Use pyarrow directly for more robust writing\n",
    "    try:\n",
    "        import pyarrow as pa\n",
    "        import pyarrow.parquet as pq\n",
    "        table = pa.Table.from_pandas(df, preserve_index=False)\n",
    "        pq.write_table(table, filepath)\n",
    "    except Exception as e:\n",
    "        print(f\"PyArrow write failed ({e}), trying pandas directly...\")\n",
    "        df.to_parquet(filepath, index=False, engine='pyarrow')\n",
    "    \n",
    "    print(f\"Written {len(df):,} rows to {filepath}\")\n",
    "    return filepath\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# MAIN MERGE FUNCTION\n",
    "# =============================================================================\n",
    "\n",
    "def merge_trades_with_eod(\n",
    "    trades_df: pd.DataFrame,\n",
    "    ticker: str,\n",
    "    date_str: str,\n",
    "    eod_path: str\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Merge trades for a specific underlying with EOD chain data.\n",
    "    \n",
    "    Only merges with actual trades - no phantom rows for untraded options.\n",
    "    \n",
    "    Args:\n",
    "        trades_df: DataFrame containing trades for all underlyings\n",
    "        ticker: Underlying ticker to process (e.g., 'AAPL')\n",
    "        date_str: Trade date in YYYY-MM-DD format\n",
    "        eod_path: Path to EOD chain files\n",
    "        \n",
    "    Returns:\n",
    "        Merged DataFrame with trades enriched with EOD data\n",
    "    \"\"\"\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Processing {ticker} for {date_str}\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    # 1. Filter trades for this underlying\n",
    "    if 'underlying' in trades_df.columns:\n",
    "        ticker_trades = trades_df[trades_df['underlying'] == ticker].copy()\n",
    "    else:\n",
    "        # Extract underlying from option ticker if not present\n",
    "        trades_df['_underlying'] = trades_df['ticker'].apply(extract_underlying_from_option_ticker)\n",
    "        ticker_trades = trades_df[trades_df['_underlying'] == ticker].copy()\n",
    "        ticker_trades = ticker_trades.drop(columns=['_underlying'])\n",
    "    \n",
    "    if len(ticker_trades) == 0:\n",
    "        print(f\"No trades found for {ticker} on {date_str}\")\n",
    "        return None\n",
    "    \n",
    "    print(f\"Found {len(ticker_trades):,} trades for {ticker}\")\n",
    "    \n",
    "    # 2. Load EOD chain data for current day\n",
    "    eod_df = read_eod_chain_file(eod_path, ticker, date_str)\n",
    "    \n",
    "    if eod_df is None:\n",
    "        print(f\"No EOD chain data found for {ticker} on {date_str}\")\n",
    "        # Return trades without EOD enrichment\n",
    "        ticker_trades['open_interest_now'] = np.nan\n",
    "        ticker_trades['open_interest_yesterday'] = np.nan\n",
    "        ticker_trades['implied_volatility'] = np.nan\n",
    "        ticker_trades['grk_delta'] = np.nan\n",
    "        ticker_trades['grk_gamma'] = np.nan\n",
    "        ticker_trades['grk_theta'] = np.nan\n",
    "        ticker_trades['grk_vega'] = np.nan\n",
    "        ticker_trades['trade_date'] = date_str\n",
    "        return ticker_trades\n",
    "    \n",
    "    # 3. Load EOD chain data for previous trading day (for open_interest_yesterday)\n",
    "    prev_date = get_previous_trading_day(date_str)\n",
    "    print(f\"Previous trading day: {prev_date}\")\n",
    "    \n",
    "    eod_prev_df = read_eod_chain_file(eod_path, ticker, prev_date)\n",
    "    \n",
    "    # 4. Convert ticker formats in EOD data to match trades (OCC format)\n",
    "    # Note: EOD files use 'code' column for option contract symbols, not 'ticker'\n",
    "    eod_df['ticker_occ'] = eod_df['code'].apply(convert_to_occ_format)\n",
    "\n",
    "    if eod_prev_df is not None:\n",
    "        eod_prev_df['ticker_occ'] = eod_prev_df['code'].apply(convert_to_occ_format)\n",
    "        prev_oi_map = dict(zip(eod_prev_df['ticker_occ'], eod_prev_df['open_interest']))\n",
    "    else:\n",
    "        prev_oi_map = {}\n",
    "        print(f\"Warning: No previous day EOD data found for {ticker}\")\n",
    "    \n",
    "    # 5. Create mapping dictionaries from EOD data\n",
    "    eod_columns = ['open_interest', 'implied_volatility', 'delta', 'gamma', 'theta', 'vega']\n",
    "    available_columns = [c for c in eod_columns if c in eod_df.columns]\n",
    "    \n",
    "    eod_map = eod_df.set_index('ticker_occ')[available_columns].to_dict('index')\n",
    "    \n",
    "    # 6. Map EOD data to trades\n",
    "    ticker_trades['open_interest_now'] = ticker_trades['ticker'].map(\n",
    "        lambda x: eod_map.get(x, {}).get('open_interest', np.nan)\n",
    "    )\n",
    "    \n",
    "    ticker_trades['open_interest_yesterday'] = ticker_trades['ticker'].map(\n",
    "        lambda x: prev_oi_map.get(x, np.nan)\n",
    "    )\n",
    "    \n",
    "    ticker_trades['implied_volatility'] = ticker_trades['ticker'].map(\n",
    "        lambda x: eod_map.get(x, {}).get('implied_volatility', np.nan)\n",
    "    )\n",
    "    \n",
    "    ticker_trades['grk_delta'] = ticker_trades['ticker'].map(\n",
    "        lambda x: eod_map.get(x, {}).get('delta', np.nan)\n",
    "    )\n",
    "    \n",
    "    ticker_trades['grk_gamma'] = ticker_trades['ticker'].map(\n",
    "        lambda x: eod_map.get(x, {}).get('gamma', np.nan)\n",
    "    )\n",
    "    \n",
    "    ticker_trades['grk_theta'] = ticker_trades['ticker'].map(\n",
    "        lambda x: eod_map.get(x, {}).get('theta', np.nan)\n",
    "    )\n",
    "    \n",
    "    ticker_trades['grk_vega'] = ticker_trades['ticker'].map(\n",
    "        lambda x: eod_map.get(x, {}).get('vega', np.nan)\n",
    "    )\n",
    "    \n",
    "    # 7. Add trade date column\n",
    "    ticker_trades['trade_date'] = date_str\n",
    "    \n",
    "    # 8. Report merge statistics\n",
    "    matched = ticker_trades['open_interest_now'].notna().sum()\n",
    "    total = len(ticker_trades)\n",
    "    print(f\"EOD match rate: {matched:,}/{total:,} trades ({100*matched/total:.1f}%)\")\n",
    "    \n",
    "    return ticker_trades\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# MAIN PROCESSING FUNCTION\n",
    "# =============================================================================\n",
    "\n",
    "def process_date_range(config: dict):\n",
    "    \"\"\"\n",
    "    Process all tickers for a date range.\n",
    "    \n",
    "    Args:\n",
    "        config: Configuration dictionary\n",
    "    \"\"\"\n",
    "    start_date = config[\"start_date\"]\n",
    "    end_date = config[\"end_date\"]\n",
    "    tickers_to_process = config[\"tickers\"]\n",
    "    trades_path = config[\"trades_input_path\"]\n",
    "    eod_path = config[\"eod_chain_input_path\"]\n",
    "    output_path = config[\"output_path\"]\n",
    "    \n",
    "    # Get trading days in range\n",
    "    trading_days = get_trading_days_in_range(start_date, end_date)\n",
    "    print(f\"\\nProcessing {len(trading_days)} trading days from {start_date} to {end_date}\")\n",
    "    \n",
    "    output_files = []\n",
    "    \n",
    "    for date_str in trading_days:\n",
    "        print(f\"\\n{'#'*60}\")\n",
    "        print(f\"# DATE: {date_str}\")\n",
    "        print(f\"{'#'*60}\")\n",
    "        \n",
    "        # Load all trades for this date\n",
    "        trades_df = read_trades_file(trades_path, date_str)\n",
    "        \n",
    "        if trades_df is None:\n",
    "            print(f\"Skipping {date_str} - no trades file found\")\n",
    "            continue\n",
    "        \n",
    "        # Determine which tickers to process\n",
    "        if tickers_to_process is None:\n",
    "            # Process all unique underlyings in the trades file\n",
    "            if 'underlying' in trades_df.columns:\n",
    "                available_tickers = trades_df['underlying'].dropna().unique().tolist()\n",
    "            else:\n",
    "                trades_df['_underlying'] = trades_df['ticker'].apply(extract_underlying_from_option_ticker)\n",
    "                available_tickers = trades_df['_underlying'].dropna().unique().tolist()\n",
    "            print(f\"Found {len(available_tickers)} unique underlyings in trades data\")\n",
    "        else:\n",
    "            available_tickers = tickers_to_process\n",
    "        \n",
    "        # Process each ticker\n",
    "        for ticker in available_tickers:\n",
    "            try:\n",
    "                merged_df = merge_trades_with_eod(\n",
    "                    trades_df=trades_df,\n",
    "                    ticker=ticker,\n",
    "                    date_str=date_str,\n",
    "                    eod_path=eod_path\n",
    "                )\n",
    "                \n",
    "                if merged_df is not None and len(merged_df) > 0:\n",
    "                    output_file = write_output_parquet(merged_df, output_path, ticker, date_str)\n",
    "                    output_files.append(output_file)\n",
    "                    \n",
    "            except Exception as e:\n",
    "                print(f\"Error processing {ticker} on {date_str}: {str(e)}\")\n",
    "                import traceback\n",
    "                traceback.print_exc()\n",
    "    \n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"PROCESSING COMPLETE\")\n",
    "    print(f\"{'='*60}\")\n",
    "    print(f\"Total output files created: {len(output_files)}\")\n",
    "    \n",
    "    return output_files\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# MAIN EXECUTION\n",
    "# =============================================================================\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    \"\"\"\n",
    "    USAGE EXAMPLES:\n",
    "    \n",
    "    1. Process specific tickers for one day:\n",
    "       CONFIG[\"tickers\"] = [\"AAPL\", \"TSLA\", \"NVDA\"]\n",
    "       CONFIG[\"start_date\"] = \"2023-12-04\"\n",
    "       CONFIG[\"end_date\"] = \"2023-12-04\"\n",
    "    \n",
    "    2. Process ALL tickers for a date range:\n",
    "       CONFIG[\"tickers\"] = None\n",
    "       CONFIG[\"start_date\"] = \"2023-12-01\"\n",
    "       CONFIG[\"end_date\"] = \"2023-12-31\"\n",
    "    \n",
    "    3. Process single ticker for a month:\n",
    "       CONFIG[\"tickers\"] = [\"SPY\"]\n",
    "       CONFIG[\"start_date\"] = \"2023-12-01\"\n",
    "       CONFIG[\"end_date\"] = \"2023-12-29\"\n",
    "    \n",
    "    INPUT FILE EXPECTATIONS:\n",
    "    - Trades: {trades_input_path}/YYYY-MM-DD.parquet\n",
    "    - EOD:    {eod_chain_input_path}/{TICKER}_{DATE}.csv  (FLAT, not nested!)\n",
    "    \n",
    "    OUTPUT:\n",
    "    - {output_path}/{ticker}_comptrades_YYYY-MM-DD.parquet\n",
    "    \"\"\"\n",
    "    \n",
    "    # =========================================================================\n",
    "    # CONFIGURE YOUR RUN HERE\n",
    "    # =========================================================================\n",
    "    CONFIG.update({\n",
    "        # Date range\n",
    "        \"start_date\": \"2024-02-01\",\n",
    "        \"end_date\": \"2025-12-31\",\n",
    "        \n",
    "        # Tickers: list for specific tickers, None for all\n",
    "        \"tickers\": [\"CIFR\"],\n",
    "        \n",
    "        # Input paths - UPDATE THESE FOR YOUR ENVIRONMENT\n",
    "        \"trades_input_path\": r\"D:\\cyclelabs_codes\\CL_20251120_siphontrades\\01_FIXINGRAWDATA\\output\",\n",
    "        \"eod_chain_input_path\": r\"D:\\cyclelabs_codes\\CL_20260116_anomalyfixed\\000_DATA01_EODHISTORICALOPTIONS\",\n",
    "        \n",
    "        # Output path - UPDATE THIS\n",
    "        \"output_path\": r\"D:\\cyclelabs_codes\\CL_20251120_siphontrades\\01_FIXINGRAWDATA\\output_mergedall\",\n",
    "    })\n",
    "    \n",
    "    # Run the merge\n",
    "    output_files = process_date_range(CONFIG)\n",
    "    \n",
    "    print(f\"\\nGenerated {len(output_files)} output files:\")\n",
    "    for f in output_files[:10]:\n",
    "        print(f\"  - {f}\")\n",
    "    if len(output_files) > 10:\n",
    "        print(f\"  ... and {len(output_files) - 10} more\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
